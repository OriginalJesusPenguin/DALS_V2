<!-- 2d57d490-04e6-454a-8f34-1620972de3dd 38d54c06-22af-4002-a03b-5564011d7980 -->
# Kendall & Gal Loss Update

1. Add CLI flag in `mesh_decoder.py` parser to toggle Kendall & Gal adaptive loss weighting (default off).
2. When the flag is active, initialize learnable sigma parameters, ensure they move with the trainer, participate in optimization, and persist through checkpoints.
3. Update the training loss assembly: keep existing weighted-sum path when the flag is off, otherwise apply `L_i' = L_i / (2 * sigma_i**2) + log(sigma_i)` to `chamfer`, `edge_length`, `quality`, and `norm` losses while leaving other terms unchanged.