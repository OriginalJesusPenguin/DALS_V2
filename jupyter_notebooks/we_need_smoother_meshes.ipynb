{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f61f7dbd",
   "metadata": {},
   "source": [
    "### Import packages for the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01874a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append('/home/ralbe/DALS/mesh_autodecoder')\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import trimesh\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from pytorch3d.io import load_objs_as_meshes\n",
    "from pytorch3d.ops import sample_points_from_meshes, SubdivideMeshes\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "\n",
    "from model.mesh_decoder import MeshDecoder\n",
    "from model.loss import mesh_bl_quality_loss\n",
    "from util.metrics import point_metrics, self_intersections\n",
    "\n",
    "from scipy.spatial import cKDTree  # Compute distance from each predicted (decoded) vertex to closest GT (target) vertex\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a7863",
   "metadata": {},
   "source": [
    "### Load checkpoint and extract info from it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a5cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_path = '/home/ralbe/DALS/mesh_autodecoder/models/MeshDecoderTrainer_2025-11-06_12-00-26.ckpt'\n",
    "\n",
    "\n",
    "checkpoint = torch.load(model_checkpoint_path,map_location='cpu')\n",
    "\n",
    "keys = list(checkpoint.keys())\n",
    "\n",
    "for key in keys:\n",
    "    \n",
    "    if key!='decoder_state_dict':\n",
    "        print(key)\n",
    "        \n",
    "hparams=checkpoint['hparams']\n",
    "latent_vectors = checkpoint['latent_vectors']\n",
    "best_epoch = checkpoint['best_epoch']\n",
    "best_loss = checkpoint['best_loss']\n",
    "train_data_path = checkpoint['train_data_path']\n",
    "val_data_path = checkpoint['val_data_path']\n",
    "train_file_names = checkpoint['train_filenames']\n",
    "latent_features = checkpoint['latent_features']\n",
    "decoder_mode = checkpoint['decoder_mode']\n",
    "template = checkpoint['template']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AND NOW PRINT THEM ALL\n",
    "\n",
    "for key in hparams.keys():\n",
    "    print(f\"{key}: {hparams[key]}\")\n",
    "print(f\"latent_vectors: {latent_vectors}\")\n",
    "print(f\"best_epoch: {best_epoch}\")\n",
    "print(f\"best_loss: {best_loss}\")\n",
    "print(f\"train_data_path: {train_data_path}\")\n",
    "print(f\"val_data_path: {val_data_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5846ed31",
   "metadata": {},
   "source": [
    "### Extract latent vectors distribution information and plot it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ead10a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have latent_vectors as a PyTorch parameter\n",
    "latent_vectors_np = latent_vectors.weight.detach().cpu().numpy()\n",
    "num_vectors, latent_dim = latent_vectors_np.shape\n",
    "\n",
    "# Prepare data for 3D scatter\n",
    "k_indices = np.repeat(np.arange(latent_dim), num_vectors)      # x-axis: latent dimension index\n",
    "values = latent_vectors_np.T.flatten()                         # y-axis: latent value\n",
    "vector_indices = np.tile(np.arange(num_vectors), latent_dim)   # z-axis: vector index\n",
    "\n",
    "# Calculate mean and std for each latent dimension\n",
    "means = latent_vectors_np.mean(axis=0)  # shape: (latent_dim,)\n",
    "stds = latent_vectors_np.std(axis=0)    # shape: (latent_dim,)\n",
    "\n",
    "# Create list of figure traces\n",
    "scatter_trace = go.Scatter3d(\n",
    "    x=k_indices,\n",
    "    y=values,\n",
    "    z=vector_indices,\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        color=values,\n",
    "        colorscale='Viridis',\n",
    "        opacity=0.6,\n",
    "        colorbar=dict(title='Latent Value')\n",
    "    ),\n",
    "    name='Values'\n",
    ")\n",
    "\n",
    "# NEW: Show mean ± std as vertical error bars instead of the shaded band\n",
    "\n",
    "mean_trace = go.Scatter3d(\n",
    "    x=np.arange(latent_dim),\n",
    "    y=means,\n",
    "    z=np.full(latent_dim, num_vectors // 2),\n",
    "    mode='markers+lines',\n",
    "    marker=dict(size=6, color='red'),\n",
    "    line=dict(color='red', width=3),\n",
    "    name='Mean'\n",
    ")\n",
    "\n",
    "# Add error bars for mean ± std as separate 'bar' traces at each x (dim k), at mid z\n",
    "error_bar_traces = []\n",
    "for k in range(latent_dim):\n",
    "    error_bar_traces.append(\n",
    "        go.Scatter3d(\n",
    "            x=[k, k],\n",
    "            y=[means[k] - stds[k], means[k] + stds[k]],\n",
    "            z=[num_vectors // 2, num_vectors // 2],\n",
    "            mode='lines',\n",
    "            line=dict(color='orange', width=4),\n",
    "            showlegend=(k==0),\n",
    "            name='Mean ± Std' if k == 0 else None,\n",
    "            hoverinfo='none'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create interactive 3D scatter plot with mean and std error bars\n",
    "fig = go.Figure(data=[scatter_trace, mean_trace] + error_bar_traces)\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Interactive 3D Scatter: Latent Vector Values per Dimension (Mean ± Std as Error Bars)',\n",
    "    scene=dict(\n",
    "        xaxis_title='Latent Vector Dimension k',\n",
    "        yaxis_title='Latent Value',\n",
    "        zaxis_title='Vector Index'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=0, t=40),\n",
    "    legend=dict(x=0.01, y=0.99),\n",
    "    height=1200,\n",
    "    width=1200\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c4237",
   "metadata": {},
   "source": [
    "### Check out for a specific training mesh index, the saved z associated with that mesh. \n",
    "NOTE: this result is just the saved representation WITHOUT test-time inference. \n",
    "NOTE 2 : For good reconstruction metrics, more than 10k metric_samples are advised\n",
    "TO-DO: Add a test-time optimization for the training meshes as well to have more accurate meshes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c00860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "latent_index = 10  # choose which latent code to decode\n",
    "output_dir = \"notebook_decoded_mesh\"\n",
    "metric_samples = 20_000\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Instantiate decoder and template ---\n",
    "hparams = checkpoint[\"hparams\"]\n",
    "decoder = MeshDecoder(\n",
    "    hparams[\"latent_features\"],\n",
    "    hparams[\"steps\"],\n",
    "    hparams[\"hidden_features\"],\n",
    "    hparams[\"subdivide\"],\n",
    "    mode=hparams[\"decoder_mode\"],\n",
    "    norm=hparams[\"normalization\"][0],\n",
    ").to(device).eval()\n",
    "decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
    "\n",
    "template = checkpoint[\"template\"].to(device)\n",
    "template = SubdivideMeshes()(template)\n",
    "\n",
    "latent_module = checkpoint[\"latent_vectors\"]\n",
    "if isinstance(latent_module, torch.nn.Embedding):\n",
    "    latent_tensor = latent_module.weight.detach()\n",
    "elif isinstance(latent_module, torch.nn.Parameter):\n",
    "    latent_tensor = latent_module.detach()\n",
    "else:\n",
    "    latent_tensor = torch.as_tensor(latent_module)\n",
    "latent_tensor = latent_tensor.to(device)\n",
    "print(f\"Latent tensor shape: {latent_tensor.shape}\")\n",
    "\n",
    "latent_vector = latent_tensor[latent_index].unsqueeze(0)\n",
    "# latent_vector[0,0]=0.0\n",
    "print(latent_vector.shape)\n",
    "print(f\"Decoding latent index {latent_index}\")\n",
    "\n",
    "# --- Decode mesh ---\n",
    "decode_start = time.time()\n",
    "with torch.no_grad():\n",
    "    decoded_mesh = decoder(template.clone(), latent_vector)[-1]\n",
    "decode_time = time.time() - decode_start\n",
    "print(f\"Decode time: {decode_time:.3f}s\")\n",
    "\n",
    "# --- Save decoded mesh ---\n",
    "mesh_filename = f\"latent_{latent_index:03d}.obj\"\n",
    "mesh_path = os.path.join(output_dir, mesh_filename)\n",
    "decoded_trimesh = trimesh.Trimesh(\n",
    "    vertices=decoded_mesh.verts_packed().cpu().numpy(),\n",
    "    faces=decoded_mesh.faces_packed().cpu().numpy(),\n",
    "    process=False,\n",
    ")\n",
    "decoded_trimesh.export(mesh_path)\n",
    "print(f\"Saved decoded mesh to {mesh_path}\")\n",
    "\n",
    "# --- Load target mesh for metrics ---\n",
    "if latent_index >= len(train_file_names):\n",
    "    raise IndexError(\n",
    "        f\"latent index {latent_index} out of range for available training meshes (0-{len(train_file_names)-1})\"\n",
    "    )\n",
    "\n",
    "target_mesh_path = os.path.join(train_data_path, train_file_names[latent_index])\n",
    "print(f\"Using target mesh: {target_mesh_path}\")\n",
    "\n",
    "target_mesh = load_objs_as_meshes([target_mesh_path], device=device)\n",
    "\n",
    "# --- Metric computation ---\n",
    "with torch.no_grad():\n",
    "    pred_samples = sample_points_from_meshes(decoded_mesh, metric_samples)\n",
    "    true_samples = sample_points_from_meshes(target_mesh, metric_samples)\n",
    "    chamfer_val = chamfer_distance(true_samples, pred_samples)[0] * 10000\n",
    "    metric_dict = point_metrics(true_samples, pred_samples, [0.01, 0.02])\n",
    "    bl_quality = (1.0 - mesh_bl_quality_loss(decoded_mesh)).item()\n",
    "\n",
    "decoded_mesh_cpu = decoded_mesh.cpu()\n",
    "ints_tensor, _ = self_intersections(decoded_mesh_cpu)\n",
    "faces_count = len(decoded_mesh_cpu.faces_packed())\n",
    "ints_percent = 100.0 * float(ints_tensor[0]) / max(faces_count, 1)\n",
    "\n",
    "summary = {\n",
    "    \"ChamferL2 x 10000_mean\": chamfer_val.item(),\n",
    "    \"ChamferL2 x 10000_std\": 0.0,\n",
    "    \"BL quality_mean\": bl_quality,\n",
    "    \"BL quality_std\": 0.0,\n",
    "    \"No. ints._mean\": ints_percent,\n",
    "    \"No. ints._std\": 0.0,\n",
    "    \"Precision@0.01_mean\": metric_dict[\"Precision@0.01\"].item(),\n",
    "    \"Precision@0.01_std\": 0.0,\n",
    "    \"Recall@0.01_mean\": metric_dict[\"Recall@0.01\"].item(),\n",
    "    \"Recall@0.01_std\": 0.0,\n",
    "    \"F1@0.01_mean\": metric_dict[\"F1@0.01\"].item(),\n",
    "    \"F1@0.01_std\": 0.0,\n",
    "    \"Precision@0.02_mean\": metric_dict[\"Precision@0.02\"].item(),\n",
    "    \"Precision@0.02_std\": 0.0,\n",
    "    \"Recall@0.02_mean\": metric_dict[\"Recall@0.02\"].item(),\n",
    "    \"Recall@0.02_std\": 0.0,\n",
    "    \"F1@0.02_mean\": metric_dict[\"F1@0.02\"].item(),\n",
    "    \"F1@0.02_std\": 0.0,\n",
    "    \"Search_mean\": decode_time,\n",
    "    \"Search_std\": 0.0,\n",
    "    \"Total_mean\": decode_time,\n",
    "    \"Total_std\": 0.0,\n",
    "    \"num_test_samples\": 1,\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([summary])\n",
    "metrics_path = os.path.join(output_dir, f\"latent_{latent_index:03d}_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"Metrics saved to {metrics_path}\")\n",
    "display(metrics_df.T.rename(columns={0: \"value\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b086c96e",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80750bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = True \n",
    "if visualize:\n",
    "\n",
    "\n",
    "    def mesh_wire_edges(vertices, faces):\n",
    "        # Returns unique undirected edges as (N_edges, 2) array for wireframe plotting\n",
    "        edges = np.concatenate([\n",
    "            faces[:, [0, 1]],\n",
    "            faces[:, [1, 2]],\n",
    "            faces[:, [2, 0]]\n",
    "        ], axis=0)\n",
    "        # Unique undirected edge set\n",
    "        edges = np.sort(edges, axis=1)\n",
    "        edges = np.unique(edges, axis=0)\n",
    "        return edges\n",
    "\n",
    "    decoded_vertices = decoded_mesh.verts_packed().cpu().numpy()\n",
    "    decoded_faces = decoded_mesh.faces_packed().cpu().numpy()\n",
    "    decoded_edges = mesh_wire_edges(decoded_vertices, decoded_faces)\n",
    "\n",
    "    target_vertices = target_mesh.verts_packed().cpu().numpy()\n",
    "    target_faces = target_mesh.faces_packed().cpu().numpy()\n",
    "    target_edges = mesh_wire_edges(target_vertices, target_faces)\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Wireframe for decoded mesh (all in one trace for toggle)\n",
    "    decoded_x, decoded_y, decoded_z = [], [], []\n",
    "    for edge in decoded_edges:\n",
    "        xs = decoded_vertices[edge, 0]\n",
    "        ys = decoded_vertices[edge, 1]\n",
    "        zs = decoded_vertices[edge, 2]\n",
    "        # Add start and end point and then a None to break segments for plotly\n",
    "        decoded_x.extend([xs[0], xs[1], None])\n",
    "        decoded_y.extend([ys[0], ys[1], None])\n",
    "        decoded_z.extend([zs[0], zs[1], None])\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=decoded_x, y=decoded_y, z=decoded_z,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "        name=\"Decoded\",\n",
    "        showlegend=True,\n",
    "        legendgroup=\"Decoded\"\n",
    "    ))\n",
    "\n",
    "    # Wireframe for target mesh (all in one trace, solid lines as requested)\n",
    "    target_x, target_y, target_z = [], [], []\n",
    "    for edge in target_edges:\n",
    "        xs = target_vertices[edge, 0]\n",
    "        ys = target_vertices[edge, 1]\n",
    "        zs = target_vertices[edge, 2]\n",
    "        target_x.extend([xs[0], xs[1], None])\n",
    "        target_y.extend([ys[0], ys[1], None])\n",
    "        target_z.extend([zs[0], zs[1], None])\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=target_x, y=target_y, z=target_z,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"orange\", width=2),  # now solid lines for target!\n",
    "        name=\"Target\",\n",
    "        showlegend=True,\n",
    "        legendgroup=\"Target\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Decoded vs Target Mesh Wireframes (latent {latent_index})\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\", \n",
    "            yaxis_title=\"Y\", \n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        height=900,  # Taller figure for better vertical viewing\n",
    "        width=1300,\n",
    "        legend=dict(\n",
    "            x=0.01, y=0.99,\n",
    "            itemsizing=\"constant\",\n",
    "            traceorder=\"normal\",\n",
    "            itemclick=\"toggle\",             # Single click to toggle on/off\n",
    "            itemdoubleclick=\"toggleothers\"\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    tree_gt = cKDTree(target_vertices)\n",
    "    dists, _ = tree_gt.query(decoded_vertices, k=1)  # (num_decoded_verts,)\n",
    "\n",
    "    # Map the distances to each vertex, get RGB color for each vertex with Viridis colormap\n",
    "    import matplotlib\n",
    "    viridis = matplotlib.cm.get_cmap(\"viridis\")\n",
    "    norm = matplotlib.colors.Normalize(vmin=dists.min(), vmax=dists.max())\n",
    "    vertex_rgb = viridis(norm(dists))[:, :3]  # (N,3), drop alpha\n",
    "\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # We want each *edge* to be colored according to the color of its start (or averaged endpoints)\n",
    "    # We'll use the mean of the two vertex colors for each edge\n",
    "\n",
    "    for idx, edge in enumerate(decoded_edges):\n",
    "        i0, i1 = edge\n",
    "        x = [decoded_vertices[i0, 0], decoded_vertices[i1, 0]]\n",
    "        y = [decoded_vertices[i0, 1], decoded_vertices[i1, 1]]\n",
    "        z = [decoded_vertices[i0, 2], decoded_vertices[i1, 2]]\n",
    "        color_rgb = (vertex_rgb[i0] + vertex_rgb[i1]) / 2.0  # (3,)\n",
    "        hex_color = matplotlib.colors.to_hex(color_rgb)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x, y=y, z=z,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=hex_color, width=2),\n",
    "            showlegend=False,\n",
    "            hoverinfo=\"skip\"\n",
    "        ))\n",
    "\n",
    "    # To add a colorbar, add an invisible scatter object with the color scale set\n",
    "    dummy_scatter = go.Scatter3d(\n",
    "        x=[None], y=[None], z=[None],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=0.1,\n",
    "            color=np.linspace(dists.min(), dists.max(), 100),  # dummy\n",
    "            colorscale=\"Viridis\",\n",
    "            colorbar=dict(\n",
    "                title='Dist. to Closest<br>Target Vertex'\n",
    "            ),\n",
    "            showscale=True\n",
    "        ),\n",
    "        hoverinfo=\"none\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.add_trace(dummy_scatter)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Predicted Mesh Wireframe, colored by dist. to closest GT vertex (latent {latent_index})\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\", \n",
    "            yaxis_title=\"Y\", \n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        height=900,  # Taller figure for better vertical viewing\n",
    "        width=1300\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b5f65",
   "metadata": {},
   "source": [
    "### Similar code as before, but for a test mesh, with the inference optimized mesh. Here we see that the test-time optimization really does enhance reconstruction metrics, which is apparent from the ~99.something % metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7546b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "patient_ID = 72  # choose which latent code to decode\n",
    "disease_status = 'healthy' # Choose between \"healthy\" and \"cirrhotic\"\n",
    "output_dir = \"notebook_decoded_mesh\"\n",
    "metric_samples = 12_500\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Instantiate decoder and template ---\n",
    "hparams = checkpoint[\"hparams\"]\n",
    "decoder = MeshDecoder(\n",
    "    hparams[\"latent_features\"],\n",
    "    hparams[\"steps\"],\n",
    "    hparams[\"hidden_features\"],\n",
    "    hparams[\"subdivide\"],\n",
    "    mode=hparams[\"decoder_mode\"],\n",
    "    norm=hparams[\"normalization\"][0],\n",
    ").to(device).eval()\n",
    "decoder.load_state_dict(checkpoint[\"decoder_state_dict\"])\n",
    "\n",
    "template = checkpoint[\"template\"].to(device)\n",
    "# Subdivide again for a 4-times subdivided icosahedron template\n",
    "template = SubdivideMeshes()(template)\n",
    "\n",
    "# latent_module = checkpoint[\"latent_vectors\"]\n",
    "# if isinstance(latent_module, torch.nn.Embedding):\n",
    "#     latent_tensor = latent_module.weight.detach()\n",
    "# elif isinstance(latent_module, torch.nn.Parameter):\n",
    "#     latent_tensor = latent_module.detach()\n",
    "# else:\n",
    "#     latent_tensor = torch.as_tensor(latent_module)\n",
    "# latent_tensor = latent_tensor.to(device)\n",
    "# print(f\"Latent tensor shape: {latent_tensor.shape}\")\n",
    "\n",
    "# latent_vector = latent_tensor[latent_index].unsqueeze(0)\n",
    "# latent_vector[0,0]=0.0\n",
    "# print(f\"Decoding latent index {latent_index}\")\n",
    "base_dir ='/home/ralbe/DALS/mesh_autodecoder/inference_results/meshes_MeshDecoderTrainer_2025-11-06_12-00-26/'\n",
    "latent_vector_file = base_dir +f'latents/{disease_status}_{patient_ID}_testing_latent.pt'\n",
    "target_mesh_file = base_dir +f'{disease_status}_{patient_ID}_testing_target.obj'\n",
    "decoded_mesh_file = base_dir +f'{disease_status}_{patient_ID}_testing_optimized.obj'\n",
    "latent_vector = torch.load(latent_vector_file,map_location=device)\n",
    "target_mesh = load_objs_as_meshes([target_mesh_file], device=device)\n",
    "decoded_mesh_0 = load_objs_as_meshes([decoded_mesh_file], device=device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Decode mesh ---\n",
    "decode_start = time.time()\n",
    "with torch.no_grad():\n",
    "    decoded_mesh = decoder(template.clone(), latent_vector)[-1]\n",
    "decode_time = time.time() - decode_start\n",
    "print(f\"Decode time: {decode_time:.3f}s\")\n",
    "\n",
    "# --- Save decoded mesh ---\n",
    "mesh_filename = f\"latent_{latent_index:03d}.obj\"\n",
    "mesh_path = os.path.join(output_dir, mesh_filename)\n",
    "decoded_trimesh = trimesh.Trimesh(\n",
    "    vertices=decoded_mesh.verts_packed().cpu().numpy(),\n",
    "    faces=decoded_mesh.faces_packed().cpu().numpy(),\n",
    "    process=False,\n",
    ")\n",
    "decoded_trimesh.export(mesh_path)\n",
    "print(f\"Saved decoded mesh to {mesh_path}\")\n",
    "\n",
    "# --- Load target mesh for metrics ---\n",
    "if latent_index >= len(train_file_names):\n",
    "    raise IndexError(\n",
    "        f\"latent index {latent_index} out of range for available training meshes (0-{len(train_file_names)-1})\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# --- Metric computation ---\n",
    "with torch.no_grad():\n",
    "    pred_samples = sample_points_from_meshes(decoded_mesh, metric_samples)\n",
    "    true_samples = sample_points_from_meshes(target_mesh, metric_samples)\n",
    "    chamfer_val = chamfer_distance(true_samples, pred_samples)[0] * 10000\n",
    "    metric_dict = point_metrics(true_samples, pred_samples, [0.01, 0.02])\n",
    "    bl_quality = (1.0 - mesh_bl_quality_loss(decoded_mesh)).item()\n",
    "\n",
    "decoded_mesh_cpu = decoded_mesh.cpu()\n",
    "ints_tensor, _ = self_intersections(decoded_mesh_cpu)\n",
    "faces_count = len(decoded_mesh_cpu.faces_packed())\n",
    "ints_percent = 100.0 * float(ints_tensor[0]) / max(faces_count, 1)\n",
    "\n",
    "summary = {\n",
    "    \"ChamferL2 x 10000_mean\": chamfer_val.item(),\n",
    "    \"ChamferL2 x 10000_std\": 0.0,\n",
    "    \"BL quality_mean\": bl_quality,\n",
    "    \"BL quality_std\": 0.0,\n",
    "    \"No. ints._mean\": ints_percent,\n",
    "    \"No. ints._std\": 0.0,\n",
    "    \"Precision@0.01_mean\": metric_dict[\"Precision@0.01\"].item(),\n",
    "    \"Precision@0.01_std\": 0.0,\n",
    "    \"Recall@0.01_mean\": metric_dict[\"Recall@0.01\"].item(),\n",
    "    \"Recall@0.01_std\": 0.0,\n",
    "    \"F1@0.01_mean\": metric_dict[\"F1@0.01\"].item(),\n",
    "    \"F1@0.01_std\": 0.0,\n",
    "    \"Precision@0.02_mean\": metric_dict[\"Precision@0.02\"].item(),\n",
    "    \"Precision@0.02_std\": 0.0,\n",
    "    \"Recall@0.02_mean\": metric_dict[\"Recall@0.02\"].item(),\n",
    "    \"Recall@0.02_std\": 0.0,\n",
    "    \"F1@0.02_mean\": metric_dict[\"F1@0.02\"].item(),\n",
    "    \"F1@0.02_std\": 0.0,\n",
    "    \"Search_mean\": decode_time,\n",
    "    \"Search_std\": 0.0,\n",
    "    \"Total_mean\": decode_time,\n",
    "    \"Total_std\": 0.0,\n",
    "    \"num_test_samples\": 1,\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame([summary])\n",
    "metrics_path = os.path.join(output_dir, f\"latent_{latent_index:03d}_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_path, index=False)\n",
    "print(f\"Metrics saved to {metrics_path}\")\n",
    "display(metrics_df.T.rename(columns={0: \"value\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac32231",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize = False \n",
    "\n",
    "if visualize:\n",
    "\n",
    "    # --- Visualize decoded vs target mesh as wireframes ---\n",
    "    import numpy as np\n",
    "\n",
    "    def mesh_wire_edges(vertices, faces):\n",
    "        # Returns unique undirected edges as (N_edges, 2) array for wireframe plotting\n",
    "        edges = np.concatenate([\n",
    "            faces[:, [0, 1]],\n",
    "            faces[:, [1, 2]],\n",
    "            faces[:, [2, 0]]\n",
    "        ], axis=0)\n",
    "        # Unique undirected edge set\n",
    "        edges = np.sort(edges, axis=1)\n",
    "        edges = np.unique(edges, axis=0)\n",
    "        return edges\n",
    "\n",
    "    decoded_vertices = decoded_mesh.verts_packed().cpu().numpy()\n",
    "    decoded_faces = decoded_mesh.faces_packed().cpu().numpy()\n",
    "    decoded_edges = mesh_wire_edges(decoded_vertices, decoded_faces)\n",
    "\n",
    "    target_vertices = target_mesh.verts_packed().cpu().numpy()\n",
    "    target_faces = target_mesh.faces_packed().cpu().numpy()\n",
    "    target_edges = mesh_wire_edges(target_vertices, target_faces)\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Wireframe for decoded mesh (all in one trace for toggle)\n",
    "    decoded_x, decoded_y, decoded_z = [], [], []\n",
    "    for edge in decoded_edges:\n",
    "        xs = decoded_vertices[edge, 0]\n",
    "        ys = decoded_vertices[edge, 1]\n",
    "        zs = decoded_vertices[edge, 2]\n",
    "        # Add start and end point and then a None to break segments for plotly\n",
    "        decoded_x.extend([xs[0], xs[1], None])\n",
    "        decoded_y.extend([ys[0], ys[1], None])\n",
    "        decoded_z.extend([zs[0], zs[1], None])\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=decoded_x, y=decoded_y, z=decoded_z,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"royalblue\", width=2),\n",
    "        name=\"Decoded\",\n",
    "        showlegend=True,\n",
    "        legendgroup=\"Decoded\"\n",
    "    ))\n",
    "\n",
    "    # Wireframe for target mesh (all in one trace, solid lines as requested)\n",
    "    target_x, target_y, target_z = [], [], []\n",
    "    for edge in target_edges:\n",
    "        xs = target_vertices[edge, 0]\n",
    "        ys = target_vertices[edge, 1]\n",
    "        zs = target_vertices[edge, 2]\n",
    "        target_x.extend([xs[0], xs[1], None])\n",
    "        target_y.extend([ys[0], ys[1], None])\n",
    "        target_z.extend([zs[0], zs[1], None])\n",
    "\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=target_x, y=target_y, z=target_z,\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"orange\", width=2),  # now solid lines for target!\n",
    "        name=\"Target\",\n",
    "        showlegend=True,\n",
    "        legendgroup=\"Target\"\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Decoded vs Target Mesh Wireframes (latent {latent_index})\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\", \n",
    "            yaxis_title=\"Y\", \n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        height=900,  # Taller figure for better vertical viewing\n",
    "        width=1300,\n",
    "        legend=dict(\n",
    "            x=0.01, y=0.99,\n",
    "            itemsizing=\"constant\",\n",
    "            traceorder=\"normal\",\n",
    "            itemclick=\"toggle\",             # Single click to toggle on/off\n",
    "            itemdoubleclick=\"toggleothers\"\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    tree_gt = cKDTree(target_vertices)\n",
    "    dists, _ = tree_gt.query(decoded_vertices, k=1)  # (num_decoded_verts,)\n",
    "\n",
    "    # Map the distances to each vertex, get RGB color for each vertex with Viridis colormap\n",
    "    import matplotlib\n",
    "    viridis = matplotlib.cm.get_cmap(\"viridis\")\n",
    "    norm = matplotlib.colors.Normalize(vmin=dists.min(), vmax=dists.max())\n",
    "    vertex_rgb = viridis(norm(dists))[:, :3]  # (N,3), drop alpha\n",
    "\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # We want each *edge* to be colored according to the color of its start (or averaged endpoints)\n",
    "    # We'll use the mean of the two vertex colors for each edge\n",
    "\n",
    "    for idx, edge in enumerate(decoded_edges):\n",
    "        i0, i1 = edge\n",
    "        x = [decoded_vertices[i0, 0], decoded_vertices[i1, 0]]\n",
    "        y = [decoded_vertices[i0, 1], decoded_vertices[i1, 1]]\n",
    "        z = [decoded_vertices[i0, 2], decoded_vertices[i1, 2]]\n",
    "        color_rgb = (vertex_rgb[i0] + vertex_rgb[i1]) / 2.0  # (3,)\n",
    "        hex_color = matplotlib.colors.to_hex(color_rgb)\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=x, y=y, z=z,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=hex_color, width=2),\n",
    "            showlegend=False,\n",
    "            hoverinfo=\"skip\"\n",
    "        ))\n",
    "\n",
    "    # To add a colorbar, add an invisible scatter object with the color scale set\n",
    "    dummy_scatter = go.Scatter3d(\n",
    "        x=[None], y=[None], z=[None],\n",
    "        mode=\"markers\",\n",
    "        marker=dict(\n",
    "            size=0.1,\n",
    "            color=np.linspace(dists.min(), dists.max(), 100),  # dummy\n",
    "            colorscale=\"Viridis\",\n",
    "            colorbar=dict(\n",
    "                title='Dist. to Closest<br>Target Vertex'\n",
    "            ),\n",
    "            showscale=True\n",
    "        ),\n",
    "        hoverinfo=\"none\",\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.add_trace(dummy_scatter)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"Predicted Mesh Wireframe, colored by dist. to closest GT vertex (latent {latent_index})\",\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\", \n",
    "            yaxis_title=\"Y\", \n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        height=900,  # Taller figure for better vertical viewing\n",
    "        width=1300\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8918b53c",
   "metadata": {},
   "source": [
    "### Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c3cb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent_vectors_np.shape)  # e.g. (345, 128)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Case A: Deform using the average latent vector ---\n",
    "avg_latent_vector = latent_vectors_np.mean(axis=0)\n",
    "print(\"avg latent shape\", avg_latent_vector.shape)  # e.g. (128,)\n",
    "avg_latent_tensor = torch.tensor(avg_latent_vector, dtype=torch.float32).unsqueeze(0)\n",
    "decoded_avg_mesh = decoder(template.clone(), avg_latent_tensor)[-1]\n",
    "decoded_avg_mesh_cpu = decoded_avg_mesh.cpu()\n",
    "avg_vertices = decoded_avg_mesh_cpu.verts_packed().detach().numpy()\n",
    "avg_faces = decoded_avg_mesh_cpu.faces_packed().detach().numpy()\n",
    "\n",
    "# --- Case B: Set elements 20:40 of the avg latent vector to zero, then decode ---\n",
    "lat_mod = avg_latent_vector.copy()\n",
    "lat_mod[20:40] = 0.4\n",
    "lat_mod_tensor = torch.tensor(lat_mod, dtype=torch.float32).unsqueeze(0)\n",
    "decoded_lat_mod_mesh = decoder(template.clone(), lat_mod_tensor)[-1]\n",
    "decoded_lat_mod_mesh_cpu = decoded_lat_mod_mesh.cpu()\n",
    "mod_vertices = decoded_lat_mod_mesh_cpu.verts_packed().detach().numpy()\n",
    "mod_faces = decoded_lat_mod_mesh_cpu.faces_packed().detach().numpy()\n",
    "\n",
    "def plot_wireframe(vertices, faces, title_str=\"Wireframe Mesh\", color=\"blue\"):\n",
    "    # For each face, plot each edge as a line\n",
    "    lines = []\n",
    "    for tri in faces:\n",
    "        pts = vertices[tri]\n",
    "        # Add edges: (v0,v1), (v1,v2), (v2,v0)\n",
    "        edges = [\n",
    "            (pts[0], pts[1]),\n",
    "            (pts[1], pts[2]),\n",
    "            (pts[2], pts[0]),\n",
    "        ]\n",
    "        for (p, q) in edges:\n",
    "            lines.append(go.Scatter3d(\n",
    "                x=[p[0], q[0]],\n",
    "                y=[p[1], q[1]],\n",
    "                z=[p[2], q[2]],\n",
    "                mode='lines',\n",
    "                line=dict(color=color, width=2),\n",
    "                hoverinfo='skip',\n",
    "                showlegend=False\n",
    "            ))\n",
    "    fig = go.Figure(data=lines)\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis_title=\"X\",\n",
    "            yaxis_title=\"Y\",\n",
    "            zaxis_title=\"Z\"\n",
    "        ),\n",
    "        title=title_str,\n",
    "        height=600,\n",
    "        width=900,\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "# Plot both meshes\n",
    "plot_wireframe(avg_vertices, avg_faces, title_str=\"Wireframe: avg latent vector\", color=\"blue\")\n",
    "plot_wireframe(mod_vertices, mod_faces, title_str=\"Wireframe: avg latent with [20:40]=0\", color=\"red\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34c4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh_avg = trimesh.Trimesh(\n",
    "    vertices=avg_vertices,\n",
    "    faces=avg_faces,\n",
    "    process=False,\n",
    ")\n",
    "mesh_mod = trimesh.Trimesh(\n",
    "    vertices=mod_vertices,\n",
    "    faces=mod_faces,\n",
    "    process=False,\n",
    ")\n",
    "mesh_avg.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a7031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mesh_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab34b7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e769a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesh_autodecoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
