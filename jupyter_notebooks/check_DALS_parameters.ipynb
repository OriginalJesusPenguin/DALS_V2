{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4b8965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latent_features': 128, 'steps': 1, 'subdivide': False, 'hidden_features': [724, 724, 362], 'concat_latent_at': [], 'template_subdiv': 3, 'decoder_mode': 'gcnn', 'encoding': 'none', 'encoding_order': 8, 'normalization': 'layer', 'rotate_template': True, 'remesh_every': 0, 'remesh_every_edge_length_ratio': 1.0, 'remesh_at': [], 'remesh_at_edge_length_ratio': [], 'num_epochs': 9999, 'batch_size': 8, 'weight_normal_loss': 0.01, 'weight_norm_loss': 0.001, 'weight_edge_loss': 0.01, 'weight_laplacian_loss': 0.01, 'weight_quality_loss': 0.001, 'use_kendall_gal': True, 'num_mesh_samples': 2500, 'train_batch_size': 8, 'learning_rate_net': 0.002, 'learning_rate_lv': 0.002, 'lr_reduce_factor': 0.5, 'lr_reduce_patience': 50, 'lr_reduce_min_lr': 1e-05, 'save_shapes_every': 0, 'save_shapes_dir': './saved_shapes', 'no_checkpoints': False, 'checkpoint_postfix': '', 'checkpoint_dir': '.', 'random_seed': 1337, 'resume_from': None, 'profiling': False}\n",
      "dict_keys(['decoder_state_dict', 'optimizer_state_dict', 'scheduler_state_dict', 'latent_vectors', 'template', 'hparams', 'epoch', 'best_epoch', 'best_loss', 'best_epoch_losses', 'train_data_path', 'val_data_path', 'train_filenames', 'latent_features', 'decoder_mode', 'kendall_log_sigmas'])\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "\n",
    "mesh_decoder_files_in_current_folder = glob.glob('/home/ralbe/DALS/mesh_autodecoder/models/MeshDecoderTrainer_2025-11-06_12-00*.ckpt')\n",
    "convnet_files_in_current_folder = glob.glob('ConvNet*ckpt')\n",
    "# List to hold dicts for each file\n",
    "mesh_decoder_data_list = []\n",
    "\n",
    "for file in mesh_decoder_files_in_current_folder:\n",
    "    loaded_file = torch.load(file, map_location='cpu')\n",
    "    print(loaded_file['hparams'])\n",
    "    print(loaded_file.keys())\n",
    "    row = {\n",
    "        'filename': os.path.basename(file),\n",
    "        'train_path': loaded_file['train_data_path'],\n",
    "        'val_path': loaded_file['val_data_path'],\n",
    "        'databank_size': loaded_file['latent_vectors'].weight.shape[0],\n",
    "        'databank_latent_dim': loaded_file['latent_vectors'].weight.shape[1],\n",
    "        'template_shape': loaded_file['template'].verts_packed().shape,\n",
    "        'backbone_mode': loaded_file['decoder_mode'],\n",
    "        'best_loss': loaded_file['best_loss'],\n",
    "        'best_epoch': loaded_file['best_epoch'],\n",
    "        'weight_norm_loss': loaded_file['hparams']['weight_norm_loss'],\n",
    "        'weight_normal_loss': loaded_file['hparams']['weight_normal_loss'],\n",
    "        'weight_quality_loss': loaded_file['hparams']['weight_quality_loss'],\n",
    "        'weight_laplacian_loss': loaded_file['hparams']['weight_laplacian_loss'],\n",
    "        'weight_edge_loss': loaded_file['hparams']['weight_edge_loss'],\n",
    "    }\n",
    "    mesh_decoder_data_list.append(row)\n",
    "\n",
    "mesh_decoder_df = pd.DataFrame(mesh_decoder_data_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "449ddf88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                      filename  databank_latent_dim  \\\n",
      "0  MeshDecoderTrainer_2025-11-06_12-05-56.ckpt                  128   \n",
      "\n",
      "   weight_edge_loss  best_epoch best_loss  \n",
      "0              0.01         236  7.02e-03  \n",
      "filename               MeshDecoderTrainer_2025-11-06_12-05-56.ckpt\n",
      "databank_latent_dim                                            128\n",
      "weight_edge_loss                                              0.01\n",
      "best_epoch                                                     236\n",
      "best_loss                                                 7.02e-03\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)  # This line will show full column contents\n",
    "print('\\n\\n')\n",
    "df = mesh_decoder_df[['filename', 'databank_latent_dim', 'weight_edge_loss','best_epoch','best_loss']].sort_values(['databank_latent_dim', 'weight_edge_loss']).copy()\n",
    "df['best_loss'] = df['best_loss'].apply(lambda x: f'{x:.2e}')\n",
    "print(df)\n",
    "\n",
    "print(df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "260884dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet_data_list = []\n",
    "\n",
    "for file2 in convnet_files_in_current_folder:\n",
    "    loaded_file = torch.load(file2, map_location='cpu')\n",
    "    row = {\n",
    "        'model_name': loaded_file['hparams']['model'],\n",
    "        'best_dice': loaded_file['best_metric'],\n",
    "        'ckpt_filepath': os.path.abspath(file2)\n",
    "    }\n",
    "    convnet_data_list.append(row)\n",
    "\n",
    "convnet_df = pd.DataFrame(convnet_data_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e211f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name  best_dice  \\\n",
      "0    DynUNet   0.928963   \n",
      "1    ResUNet   0.894558   \n",
      "2  SEGRESNET   0.925203   \n",
      "3  SYNVNET3D   0.917074   \n",
      "4       UNET   0.896039   \n",
      "5      UNETR   0.895987   \n",
      "6       VNet   0.935717   \n",
      "\n",
      "                                                                             ckpt_filepath  \n",
      "0    /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_DynUNet_2025-10-15_15-36.ckpt  \n",
      "1    /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_ResUNet_2025-10-15_15-36.ckpt  \n",
      "2  /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_SEGRESNET_2025-10-15_18-37.ckpt  \n",
      "3  /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_SYNVNET3D_2025-10-15_17-41.ckpt  \n",
      "4       /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_UNET_2025-10-15_16-23.ckpt  \n",
      "5      /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_UNETR_2025-10-15_15-36.ckpt  \n",
      "6       /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_VNet_2025-10-15_15-36.ckpt  \n",
      "\n",
      "\n",
      "\n",
      "model_name                                                                                     VNet\n",
      "best_dice                                                                                  0.935717\n",
      "ckpt_filepath    /home/ralbe/DALS/mesh_autodecoder/models/ConvNetTrainer_VNet_2025-10-15_15-36.ckpt\n",
      "Name: 6, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(convnet_df)\n",
    "print('\\n\\n')\n",
    "print(convnet_df.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f03ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mesh_autodecoder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
